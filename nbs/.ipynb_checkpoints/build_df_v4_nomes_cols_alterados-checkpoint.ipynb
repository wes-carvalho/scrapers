{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construção da base a partir do JSON\n",
    "\n",
    "### Células comentadas  NÃO estão no `analytics.py`\n",
    "________\n",
    "_______\n",
    "_______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:29:43.659328Z",
     "start_time": "2021-06-20T13:29:38.926121Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "import locale\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:29:43.667649Z",
     "start_time": "2021-06-20T13:29:43.661465Z"
    }
   },
   "outputs": [],
   "source": [
    "# função de processamento de texto\n",
    "\n",
    "from unicodedata import normalize\n",
    "\n",
    "def tira_acento(x):\n",
    "    \n",
    "    return normalize('NFKD', x).encode('ASCII','ignore').decode('ASCII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:29:43.735101Z",
     "start_time": "2021-06-20T13:29:43.670217Z"
    }
   },
   "outputs": [],
   "source": [
    "# função de exibição \n",
    "\n",
    "def show_all(df):\n",
    "    \n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    \n",
    "    display(df)\n",
    "    \n",
    "    pd.reset_option('display.max_colwidth')\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.max_columns')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "### 1) Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:29:47.223792Z",
     "start_time": "2021-06-20T13:29:43.737325Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "\n",
    "path = \"../../../Scraper/dados/base_completa/\"\n",
    "\n",
    "print(\"\\nLista de arquivos disponíveis para a leitura:\\n\")\n",
    "\n",
    "file_list = [str(i) + \" - \" + f for i, f in enumerate(listdir(path)) if isfile(join(path, f))]\n",
    "\n",
    "print(*file_list, sep=\"\\n\")\n",
    "\n",
    "time.sleep(0.5)\n",
    "\n",
    "num = int(input(\"\\nDigite o número correspondente ao arquivo desejado: (0-\" + str(len(file_list)-1) + \"): \"))\n",
    "\n",
    "file_path = path + file_list[num].split(\" - \")[-1]\n",
    "\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:30:21.265414Z",
     "start_time": "2021-06-20T13:30:10.999992Z"
    }
   },
   "outputs": [],
   "source": [
    "# lê o arquivo e cria lista com json de cada carro\n",
    "\n",
    "with open(file_path) as f:\n",
    "    \n",
    "    json_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:27:51.699591Z",
     "start_time": "2021-06-20T13:27:51.695778Z"
    }
   },
   "outputs": [],
   "source": [
    "# # identificando quais chaves têm listas como valores\n",
    "# # nestes casos, o json_normaliza falha, por isso é importante identificarmos\n",
    "# # antes pra fazer o flatenning\n",
    "\n",
    "# list_values = []\n",
    "# for item in json_list:\n",
    "    \n",
    "#     for key in item.keys():\n",
    "\n",
    "#         if type(item[key]) == list:\n",
    "\n",
    "#             # print(key, item[key])\n",
    "            \n",
    "#             if key not in list_values:\n",
    "                \n",
    "#                 list_values.append(key)\n",
    "                \n",
    "# if len(list_values) > 0:\n",
    "    \n",
    "#     print(\"\\nHá jsons com chaves cujos valores são listas!!\")\n",
    "#     print(\"Estas chaves são:\")\n",
    "#     print(list_values)\n",
    "          \n",
    "#     print(\"\\nVamos corrigir isso agora!\")\n",
    "    \n",
    "#     # fazendo o flattening dos valores que são listas\n",
    "\n",
    "#     for item in json_list:\n",
    "\n",
    "#         for key in list_values:\n",
    "\n",
    "#             try:\n",
    "#                 for i in range(len(item[key])):\n",
    "\n",
    "#                     item[key + \"_\" + str(i+1)] = item[key][i]\n",
    "\n",
    "#                 item.pop(key)\n",
    "\n",
    "#             except:\n",
    "\n",
    "#                 pass\n",
    "    \n",
    "#     print(\"\\nTudo corrigido! Podemos seguir com a construção do df!\")\n",
    "    \n",
    "# # se não tiver nenhuma chave com essa característíca, ótimo!\n",
    "# else:\n",
    "    \n",
    "#     print(\"\\nNão há problemas com json algum, tudo certo!\")\n",
    "#     print(\"\\nPodemos seguir diretamente com a construlção do df!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:34:21.189657Z",
     "start_time": "2021-06-20T13:33:35.330808Z"
    }
   },
   "outputs": [],
   "source": [
    "# montando o df\n",
    "\n",
    "df = pd.json_normalize(json_list)\n",
    "\n",
    "del json_list, list_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:34:21.191809Z",
     "start_time": "2021-06-20T13:33:35.681Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:27:43.249261Z",
     "start_time": "2021-06-20T13:27:43.245545Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:27:40.851720Z",
     "start_time": "2021-06-20T13:27:40.847368Z"
    }
   },
   "outputs": [],
   "source": [
    "# show_all(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:34:21.193404Z",
     "start_time": "2021-06-20T13:33:45.810Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:34:21.194706Z",
     "start_time": "2021-06-20T13:33:46.321Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(\"\\nColunas com dados missing em respectiva proporção:\")\n",
    "\n",
    "# # colunas com dados missing, apenas\n",
    "# # contagem já normalizada\n",
    "# missing = df.isnull().sum()[df.isnull().sum().apply(lambda x: True if x!=0 else False)]/df.shape[0]\n",
    "\n",
    "# # print formatado\n",
    "# missing.apply(lambda x: \"{:.2f}%\".format(x*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "### 2) Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:23:21.619931Z",
     "start_time": "2021-06-20T13:23:21.617348Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # caso queira evitar que alguma coluna seja dropada\n",
    "\n",
    "# keep = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T23:46:03.746609Z",
     "start_time": "2021-05-16T23:46:03.676153Z"
    }
   },
   "outputs": [],
   "source": [
    "# # vamos dropar as colunas que tenham mais que 50% de NaNs\n",
    "\n",
    "# threshold_drop = 0.5\n",
    "\n",
    "# print(\"\\nColunas com proporção de NaNs maior que o threshold de {:.0f}%:\\n\".format(threshold_drop*100))\n",
    "\n",
    "# display(missing[missing>threshold_drop].apply(lambda x: \"{:.2f}%\".format(x*100)))\n",
    "\n",
    "# drop_nans = missing[missing>threshold_drop].index.tolist()\n",
    "\n",
    "# # evitando que colunas em \"keep\" sejam dropadas\n",
    "# drop_nans = [x for x in drop_nans if x not in keep]\n",
    "\n",
    "# # dropando!\n",
    "# df = df.drop(columns=drop_nans)\n",
    "\n",
    "# print(\"\\nColunas acima dropadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T23:46:03.817630Z",
     "start_time": "2021-05-16T23:46:03.748458Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for item in df.columns.tolist():\n",
    "    \n",
    "#     print(f'\"{item}\" : \"\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:35:54.508885Z",
     "start_time": "2021-06-20T13:35:53.878892Z"
    }
   },
   "outputs": [],
   "source": [
    "# renomeando colunas\n",
    "\n",
    "rename_dic = {  \"long_comment\" : \"Comentário\",\n",
    "                \"fipe_percent\" : \"(%) Tabela FIPE\",\n",
    "                \"price\" : \"Preço\",\n",
    "                \"unico_dono\" : \"Único Dono\",\n",
    "                \"ipva_pago\" : \"IPVA Pago\",\n",
    "                \"aceita_troca\" : \"Aceita Troca\",\n",
    "                \"combustivel\" : \"Combustível\",\n",
    "                \"motor\" : \"Motor\",\n",
    "                \"cilindrada\" : \"Cilindrada\",\n",
    "                \"valvulas\" : \"Válvulas\",\n",
    "                \"specification.title\" : \"Título do Anúncio\",\n",
    "                \"specification.make.value\" : \"Marca\",\n",
    "                \"specification.model.value\" : \"Modelo\",\n",
    "                \"specification.version.value\" : \"Versão\",\n",
    "                \"specification.year_fabrication\" : \"Ano Fabricação\",\n",
    "                \"specification.year_model\" : \"Ano Modelo\",\n",
    "                \"specification.odometer\" : \"Km\",\n",
    "                \"specification.transmission\" : \"Transmissão\",\n",
    "                \"specification.number_ports\" : \"N° Portas\",\n",
    "                \"specification.body_type\" : \"Categoria\",\n",
    "                \"specification.armored\" : \"Blindado\",\n",
    "                \"specification.color.primary\" : \"Cor\",\n",
    "                \"seller.seller_type\" : \"Vendedor Tipo\",\n",
    "                \"seller.city\" : \"Cidade\",\n",
    "                \"seller.state\" : \"Estado\",\n",
    "                \"seller.dealer_score\" : \"Dealer Score\",\n",
    "                \"seller.car_delivery\" : \"Car Delivery\",\n",
    "                \"seller.troca_com_troco\" : \"Troca Com Troco\",\n",
    "                \"seller.exceeded_plan\" : \"Exceed Plan\",\n",
    "                \"financiado\" : \"Financiado\",\n",
    "                \"licenciado\" : \"Licenciado\"}\n",
    "\n",
    "df = df.rename(columns=rename_dic)\n",
    "\n",
    "# determinando a ordem \n",
    "# tá comentado, achei desnecessário\n",
    "\n",
    "cols_select = [ # atributos gerais\n",
    "               'Título do Anúncio','Marca', 'Modelo', \n",
    "               'Versão', 'Ano Fabricação', 'Ano Modelo',\n",
    "               'Km', 'Transmissão', 'N° Portas', \n",
    "               'Categoria', 'Blindado', 'Cor',\n",
    "               'Combustível', 'Motor', 'Cilindrada', 'Válvulas',\n",
    "                # preço\n",
    "               'Preço', '(%) Tabela FIPE',\n",
    "                # 'preco_busca', \n",
    "                # flags binarias\n",
    "               'Único Dono', 'IPVA Pago', 'Aceita Troca', 'Financiado', 'Licenciado'\n",
    "                # info vendedor\n",
    "               'Vendedor Tipo', 'Cidade', 'Estado', 'Dealer Score',  \n",
    "                # extras\n",
    "               'Car Delivery', 'Troca Com Troco', 'Exceed Plan', 'Comentário',\n",
    "                # 'exceeded_plan'\n",
    "                ]\n",
    "\n",
    "# pra garantir que tem apenas as colunas que existem (que nao foram dropadas antes)\n",
    "cols_select = [item for item in cols_select if item in df.columns]\n",
    "\n",
    "df = df[cols_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:36:02.202326Z",
     "start_time": "2021-06-20T13:36:02.197148Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:36:05.212164Z",
     "start_time": "2021-06-20T13:36:05.209897Z"
    }
   },
   "outputs": [],
   "source": [
    "# # basse com todas as infos acima, de cada carro\n",
    "\n",
    "# df.to_excel(\"relatorio_completo.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:36:06.224201Z",
     "start_time": "2021-06-20T13:36:05.546483Z"
    }
   },
   "outputs": [],
   "source": [
    "# isso vai auxiliar na correção dos dtypes\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:36:14.707532Z",
     "start_time": "2021-06-20T13:36:14.204154Z"
    }
   },
   "outputs": [],
   "source": [
    "# ajustando dtypes\n",
    "\n",
    "df[\"Ano Fabricação\"] = df[\"Ano Fabricação\"].astype(int)\n",
    "\n",
    "df[\"Ano Modelo\"] = df[\"Ano Modelo\"].astype(int)\n",
    "\n",
    "df[\"N° Portas\"] = df[\"N° Portas\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:36:16.298168Z",
     "start_time": "2021-06-20T13:36:15.838271Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:36:23.791175Z",
     "start_time": "2021-06-20T13:36:23.788785Z"
    }
   },
   "outputs": [],
   "source": [
    "# # avaliando stats descritivas procurando outliers absurdos\n",
    "\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:36:26.503366Z",
     "start_time": "2021-06-20T13:36:26.500791Z"
    }
   },
   "outputs": [],
   "source": [
    "# aux = df[df[\"Preço\"] > 1e8][[\"Marca\", \"Modelo\", \"Ano Fabricação\", \"Preço\"]]\n",
    "\n",
    "# aux[\"Preço\"] = aux[\"Preço\"].apply(lambda x: locale.currency(x, grouping=True))\n",
    "\n",
    "# display(aux)\n",
    "\n",
    "# del aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:36:31.401082Z",
     "start_time": "2021-06-20T13:36:31.397941Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:36:43.379704Z",
     "start_time": "2021-06-20T13:36:42.077031Z"
    }
   },
   "outputs": [],
   "source": [
    "# separando dataframes pelo preço\n",
    "\n",
    "df_mto_caro = df[df[\"Preço\"] >= 1e6]\n",
    "\n",
    "df_normal = df[df[\"Preço\"] < 1e6]\n",
    "\n",
    "# seguindo apenas com os carros que custam menos que 1 MM\n",
    "df = df_normal.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:36:43.386208Z",
     "start_time": "2021-06-20T13:36:43.382002Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mto_caro.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:36:43.453228Z",
     "start_time": "2021-06-20T13:36:43.388544Z"
    }
   },
   "outputs": [],
   "source": [
    "df_normal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "### 4) Análise preliminar - marcas e modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:37:20.481371Z",
     "start_time": "2021-06-20T13:37:15.588663Z"
    }
   },
   "outputs": [],
   "source": [
    "# dic de dfs pra cada marca\n",
    "# estrutura: {\"marca\" : df_com_marca_filtrada}\n",
    "\n",
    "marcas = df[\"Marca\"].unique().tolist()\n",
    "\n",
    "df_marcas = {marca: df[df[\"Marca\"] == marca] for marca in marcas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:38:07.568563Z",
     "start_time": "2021-06-20T13:37:51.076362Z"
    }
   },
   "outputs": [],
   "source": [
    "# dic com a seguinte estrutura: {\"marca\": {\"modelo_i\" : df_modelo_i.describe()}}\n",
    "\n",
    "# essa célula pode demorar um pouquinho...\n",
    "\n",
    "modelos_describe = {marca : \n",
    "                           {modelo: df_marcas[marca].loc[df_marcas[marca][\"Modelo\"] == modelo].describe() \n",
    "                            for modelo in df_marcas[marca][\"Modelo\"].unique().tolist()}\n",
    "                    for marca in marcas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:38:11.176109Z",
     "start_time": "2021-06-20T13:38:11.171954Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nMarcas disponíveis:\\n\")\n",
    "\n",
    "print(list(modelos_describe.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:38:11.528319Z",
     "start_time": "2021-06-20T13:38:11.523362Z"
    }
   },
   "outputs": [],
   "source": [
    "# pegando modelos de determinada marca \n",
    "\n",
    "print(list(modelos_describe[\"HYUNDAI\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:38:13.788452Z",
     "start_time": "2021-06-20T13:38:13.667388Z"
    }
   },
   "outputs": [],
   "source": [
    "# pegando stats de determinado modelo\n",
    "\n",
    "modelos_describe[\"HYUNDAI\"]['HB20']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exportando as estatísticas descritivas por marca e modelo (sem demais agrupamentos)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:38:57.175551Z",
     "start_time": "2021-06-20T13:38:47.932058Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_export_stats = pd.DataFrame()\n",
    "\n",
    "# for marca in modelos_describe.keys():\n",
    "    \n",
    "#     for modelo in modelos_describe[marca].keys():\n",
    "\n",
    "#         aux = modelos_describe[marca][modelo].copy()\n",
    "        \n",
    "#         aux.loc[\"count\", \"Ano\"] = aux.loc[\"count\"].dropna().max()\n",
    "#         aux.loc[\"count\", aux.columns[1:]] = \"-\"\n",
    "        \n",
    "#         aux = aux.reset_index(drop=False).rename(columns={\"index\":\"stat\"})\n",
    "\n",
    "#         aux[\"Marca\"] = marca\n",
    "\n",
    "#         aux[\"Modelo\"] = modelo\n",
    "\n",
    "#         aux = aux[[\"Marca\", \"Modelo\"] + aux.columns.tolist()[:-2]]\n",
    "        \n",
    "#         df_export_stats = pd.concat([df_export_stats, aux])\n",
    "        \n",
    "# del aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:39:23.854287Z",
     "start_time": "2021-06-20T13:39:23.851600Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_export_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:22:01.786462Z",
     "start_time": "2021-04-05T00:21:58.994474Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_export_stats = df_export_stats.sort_values([\"marca\", \"modelo\"])\n",
    "\n",
    "# # formatando exibição de dados\n",
    "\n",
    "# df_export_stats[\"fipe_perc\"] = df_export_stats[\"fipe_perc\"].apply(lambda x: \n",
    "#                                                                   \"{:.1f}%\".format(x) if str(x) not in [\"nan\", \"-\"] \n",
    "#                                                                   else \"-\")\n",
    "\n",
    "# for col in [\"ano\", \"ano_modelo\", \"num_portas\"]:\n",
    "    \n",
    "#     df_export_stats[col] = df_export_stats[col].apply(lambda x: \n",
    "#                                                       int(x) if str(x) not in [\"nan\", \"-\"]\n",
    "#                                                       else \"-\")\n",
    "    \n",
    "# df_export_stats[\"preco\"] = df_export_stats[\"preco\"].apply(lambda x: \n",
    "#                                                           locale.currency(x, grouping=True) if str(x) not in [\"nan\", \"-\"] \n",
    "#                                                           else \"-\")\n",
    "\n",
    "# df_export_stats[\"km\"] = df_export_stats[\"km\"].apply(lambda x: \n",
    "#                                                     locale.format_string(\"%.2f\", x, grouping=True) if str(x) not in [\"nan\", \"-\"] \n",
    "#                                                     else \"-\")\n",
    "\n",
    "# df_export_stats[\"score_vendedor\"] = df_export_stats[\"score_vendedor\"].apply(lambda x: \n",
    "#                                                                             round(x, 2) if str(x) not in [\"nan\", \"-\"] \n",
    "#                                                                             else \"-\")\n",
    "\n",
    "# df_export_stats = df_export_stats.fillna(\"-\")\n",
    "\n",
    "# # export\n",
    "# data_hora = file_path.split(\"/\")[-1].split(\"WEBMOTORS-\")[-1].split(\".json\")[0]\n",
    "\n",
    "# df_export_stats.to_excel(\"./outputs/stats_{}.xlsx\".format(data_hora), index=False)\n",
    "\n",
    "# del df_export_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T13:41:39.002009Z",
     "start_time": "2021-06-20T13:41:38.996809Z"
    }
   },
   "outputs": [],
   "source": [
    "df_marcas[\"HONDA\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes alterados das colunas\n",
    "\n",
    "# groupby - {marca: {modelo_i :  groupby_i(ano, cilindrada, combustivel)}}\n",
    "# esse tbm demora um pouco,,\n",
    "\n",
    "# características que definem um carro (\"RG do carro\")\n",
    "rg = \"Marca, Modelo, Ano Modelo, Transmissão, Categoria, Blindado, N° Portas, Cilindrada, Combustível, Estado\".split(\", \")\n",
    "\n",
    "marca_modelo_ano = {marca : \n",
    "                        {modelo: \n",
    "                                 df_marcas[marca][df_marcas[marca][\"Modelo\"] == modelo].groupby(rg)[[\"Km\",\n",
    "                                                                                                     \"Preço\",\n",
    "                                                                                                     \"(%) Tabela FIPE\"]].agg([\"count\", \n",
    "                                                                                                                        \"mean\",\n",
    "                                                                                                                        \"min\",\n",
    "                                                                                                                        \"max\",\n",
    "                                                                                                                        np.median,\n",
    "                                                                                                                        np.std]) \n",
    "                        for modelo in df_marcas[marca][\"Modelo\"].unique().tolist()}\n",
    "                    for marca in marcas}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tabela final de groupbys - export__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:45:09.220547Z",
     "start_time": "2021-04-05T00:44:51.882802Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_export = pd.DataFrame()\n",
    "\n",
    "for marca in marca_modelo_ano.keys():\n",
    "    \n",
    "    for modelo in marca_modelo_ano[marca].keys():\n",
    "        \n",
    "        df_export = pd.concat([df_export, marca_modelo_ano[marca][modelo]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:43:18.060706Z",
     "start_time": "2021-04-05T00:42:56.818502Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_export_view = df_export.copy()\n",
    "\n",
    "# fill nan\n",
    "df_export_view = df_export_view.fillna(\"-\")\n",
    "\n",
    "# formatando dadosf\n",
    "for col in df_export_view.columns:\n",
    "    \n",
    "    if col[0] == \"preco\":\n",
    "    \n",
    "        df_export_view.loc[:, \n",
    "                      col] = df_export_view.loc[:, \n",
    "                                            col].apply(lambda x: \n",
    "                                                       locale.currency(x, grouping=True) if type(x) == float\n",
    "                                                       else (x if type(x) == int else \"-\"))\n",
    "    else:\n",
    "        \n",
    "        df_export_view.loc[:, \n",
    "                      col] = df_export_view.loc[:, \n",
    "                                            col].apply(lambda x:\n",
    "                                                       locale.format_string(\"%.2f\", x, grouping=True) if type(x) == float\n",
    "                                                       else (x if type(x) == int else \"-\"))\n",
    "\n",
    "\n",
    "# flattening columns\n",
    "df_export_view.columns = ['_'.join(col).strip() for col in df_export_view.columns.values]\n",
    "\n",
    "# flatenning indexes\n",
    "df_export_view = df_export_view.reset_index()\n",
    "        \n",
    "# ordenando\n",
    "df_export_view = df_export_view.sort_values([\"marca\", \"modelo\", \"preco_count\"])\n",
    "\n",
    "# export\n",
    "data_hora = file_path.split(\"/\")[-1].split(\"WEBMOTORS-\")[-1].split(\".json\")[0]\n",
    "\n",
    "df_export_view.to_excel(\"./outputs/report_{}.xlsx\".format(data_hora), index=False)\n",
    "\n",
    "del df_export_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "# TO DO\n",
    "\n",
    "pegar o dicionario acima, e pegar quais exemplares têm maior std de preço (ordenar).\n",
    "\n",
    "- olhar tb os counts.\n",
    "\n",
    "daí, rodar o dbscan abaixo rodado pra cada linha do grpupby acima (ou pegar dos 200 maiores std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:45:09.240447Z",
     "start_time": "2021-04-05T00:45:09.222478Z"
    }
   },
   "outputs": [],
   "source": [
    "# flattening columns\n",
    "df_export.columns = ['_'.join(col).strip() for col in df_export.columns.values]\n",
    "\n",
    "# flatenning indexes\n",
    "df_export = df_export.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:48:49.747876Z",
     "start_time": "2021-04-05T00:48:49.739108Z"
    }
   },
   "outputs": [],
   "source": [
    "df_export = df_export.sort_values([\"preco_std\", \"preco_count\"], ascending=False)\n",
    "\n",
    "# amostra minima\n",
    "n_min = 30\n",
    "df_export = df_export[df_export[\"preco_count\"] > n_min]\n",
    "\n",
    "# top N maiores std com amostra minima de 30 carros\n",
    "std_N = 100\n",
    "std_topN = df_export.head(std_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:50:43.092546Z",
     "start_time": "2021-04-05T00:50:43.066894Z"
    }
   },
   "outputs": [],
   "source": [
    "std_topN[rg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "__Vamos pegar as linhas do df acima (segundo o RG de cada linha)__\n",
    "\n",
    "Ou seja, vamos pegar os `std_N` exemplares de carros (com RG determinado) que têm maior std de preço - indicativo de maior amplitude da distribuição, mais provável de encontrarmos outliers\n",
    "\n",
    "Destas, vamos rodar o DBSCAN pra cada modelo. Com isso, encontraremos outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:52:52.470485Z",
     "start_time": "2021-04-05T00:52:52.464296Z"
    }
   },
   "outputs": [],
   "source": [
    "std_topN.iloc[0][rg].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:12:07.127118Z",
     "start_time": "2021-04-05T01:10:40.508338Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "topN_dict = {}\n",
    "\n",
    "for i in range(std_topN.shape[0]):\n",
    "    \n",
    "    rg_data = std_topN.iloc[i][rg].to_dict()\n",
    "    \n",
    "    marca = rg_data[\"marca\"]\n",
    "    modelo = rg_data[\"modelo\"]\n",
    "    \n",
    "    print(\"\\n#############################################################\")\n",
    "    print(\"#############################################################\")\n",
    "    print(\"\\nRG:\\n\")\n",
    "    for key, value in rg_data.items():\n",
    "        print(key, \":\", value)\n",
    "    print(\"\\n\")\n",
    "    print(\"#############################################################\")\n",
    "    print(\"#############################################################\\n\")\n",
    "    \n",
    "    aux = std_topN.iloc[[i]][rg].merge(df, on=rg, how=\"inner\").copy()\n",
    "    \n",
    "    #################################################################################\n",
    "#     # visualizando preço vs km com hue de ano\n",
    "#     f = sns.scatterplot(data=aux, y=\"preco\", x=\"km\", \n",
    "#                         hue=\"ano\", palette=\"rainbow\")\n",
    "\n",
    "#     ax = plt.gca()\n",
    "#     ax.set_title(marca + \" - \" + modelo)\n",
    "\n",
    "#     plt.show()\n",
    "    #################################################################################\n",
    "\n",
    "    # clustering\n",
    "\n",
    "    # selecionando features - apenas numeric & bool\n",
    "    X = aux.select_dtypes(include=[np.number, np.bool]).copy()\n",
    "\n",
    "    # selecionando apenas algumas cols - sempre inclua preco!\n",
    "    cols_features = [\"preco\", \"km\"]\n",
    "    X = aux[cols_features]\n",
    "\n",
    "    # preenchendo NaNs\n",
    "    cols_with_nan = X.isnull().any(axis=0)[X.isnull().any(axis=0) == True].index\n",
    "\n",
    "    for col in cols_with_nan:\n",
    "\n",
    "        # definindo os atributos pro cruzamento\n",
    "        cols = ['transmissao', 'categoria', 'blindado', 'cilindrada', 'combustivel']\n",
    "\n",
    "        # fazendo o agrupamento\n",
    "        media_col = aux.groupby(cols)[[col]].mean().reset_index()\n",
    "\n",
    "        # sub-base com valores missing de \"col\", e apenas as colunas de cruzamento\n",
    "        X_col_missing = aux.loc[X[col].isnull()][cols]\n",
    "\n",
    "        # fazendo o cruzamento\n",
    "        valores_a_preencher = X_col_missing.merge(media_col, \n",
    "                                                  on=cols, \n",
    "                                                  how=\"left\").set_index(X_col_missing.index)[col]\n",
    "\n",
    "        # preenchendo vazio com as médias\n",
    "        X.loc[df[col].isnull(), col] = valores_a_preencher\n",
    "\n",
    "    # normalização\n",
    "    X = pd.DataFrame(StandardScaler().fit_transform(X), columns = X.columns, index= X.index)\n",
    "\n",
    "    #################################################################################\n",
    "#     # visualizando a normalização\n",
    "#     f = sns.scatterplot(data=X, y=\"preco\", x=\"km\", palette=\"rainbow\")\n",
    "\n",
    "#     ax = plt.gca()\n",
    "#     ax.set_title(marca + \" - \" + modelo)\n",
    "\n",
    "#     plt.show()\n",
    "    #################################################################################\n",
    "\n",
    "    # modelagem\n",
    "    db = DBSCAN(eps=0.5, min_samples=2, metric=\"euclidean\").fit(X)\n",
    "\n",
    "    # cluster labels\n",
    "    aux[\"cluster\"] = db.labels_\n",
    "\n",
    "    #################################################################################\n",
    "    # visualizando preço vs km com hue de cluster\n",
    "    f = sns.scatterplot(data=aux, y=\"preco\", x=\"km\", \n",
    "                        hue=\"cluster\", palette=\"rainbow\")\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(marca + \" - \" + modelo)\n",
    "\n",
    "    plt.show()\n",
    "    #################################################################################\n",
    "\n",
    "    # atualiza o dict com o aux\n",
    "    topN_dict[\"|\".join([str(x) for x in rg_data.values()])] = aux\n",
    "        \n",
    "del aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:09:34.370690Z",
     "start_time": "2021-04-05T01:09:34.363527Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(topN_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:15:53.941660Z",
     "start_time": "2021-04-05T01:15:53.618247Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aux = topN_dict['TOYOTA|HILUX|2020|Automática|Picape|N|4|2.8|DIESEL']\n",
    "\n",
    "aux2 = aux[aux[\"cluster\"] == -1][[\"marca\", \"modelo\", \"ano\", \"km\", \"preco\"]].sort_values([\"km\", \"preco\"])\n",
    "\n",
    "# aux2 = pd.DataFrame(StandardScaler().fit_transform(aux2), columns = aux2.columns, index= aux2index)\n",
    "\n",
    "print(\"\\nOutliers:\")\n",
    "\n",
    "aux2[\"km\"] = aux2[\"km\"].apply(lambda x: locale.format_string(\"%d\", x, grouping=True))\n",
    "aux2[\"preco\"] = aux2[\"preco\"].apply(lambda x: locale.currency(x, grouping=True))\n",
    "\n",
    "display(aux2)\n",
    "\n",
    "f = sns.scatterplot(data=aux, y=\"preco\", x=\"km\", \n",
    "                    hue=\"cluster\", palette=\"rainbow\")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_title(marca + \"-\" + modelo)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "\n",
    "__________\n",
    "\n",
    "\n",
    "____________\n",
    "\n",
    "__API FIPE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T17:31:22.433813Z",
     "start_time": "2021-04-04T17:31:20.447398Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "resposta = requests.get(\"https://fipeapi.appspot.com/api/1/carros/veiculos/21.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T17:31:22.592630Z",
     "start_time": "2021-04-04T17:31:22.437769Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resposta.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
